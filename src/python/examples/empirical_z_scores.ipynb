{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following workbooks performs a bulk differential expression analysis for Teton cytoprofiling cell output. Rather than explicitly modeling the distribution of counts, this approach evaluates the changes in average counts across conditions, and assesses the change of each target relative to how much change is observed for most genes. This relies on two assumptions\n",
    "* Most targets are not changing across the conditions\n",
    "* Homoscedasticity of log-transformed counts\n",
    "\n",
    "Briefly, the analysis below will\n",
    "* Peform default filtering of cells (by area, assigned counts, and assigned rate)\n",
    "* Normalize cells by assigned counts and samples by median of ratios\n",
    "* Calculate log ratio for each targets\n",
    "* Estimate standard deviation from MAD of log ratios across all targets\n",
    "* Normalize each log ratio by standard deviation and report Z score\n",
    "\n",
    "To use the workbook, update the values for hte following fields in the cell below\n",
    "* cell_stats_file: path to cytoprofiling RawCellStats.parquet output (typically found in Cytoprofiling/Instrument/RawCellStats.parquet in the Teton output directory)\n",
    "* batch_names: Batches to include in the analysis\n",
    "* control : Label of well to use as control\n",
    "* cases : Labels of wells to use as cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_stats_file = \"/path/to/RawCellStats.parquet\"\n",
    "run_name = \"run_name\"\n",
    "\n",
    "# RNA batches\n",
    "batch_names = [\"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\",]\n",
    "\n",
    "#\n",
    "# Well labels for control and cases\n",
    "#\n",
    "control = \"control_label\"\n",
    "cases = [\"case_label1\", \"case_label_2\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from cytoprofiling import get_wells, filter_cells, get_default_normalization_targets, normalize_cells_by_aggregated_counts, normalize_wells_by_median_of_ratios\n",
    "\n",
    "#\n",
    "# load cell table\n",
    "#\n",
    "df = pd.read_parquet(cell_stats_file)\n",
    "\n",
    "#\n",
    "# load the data\n",
    "#\n",
    "well2label = {}\n",
    "for well in get_wells(df):\n",
    "    well2label[well] = df[\"WellLabel\"][df[\"Well\"] == well].unique()[0]\n",
    "\n",
    "#\n",
    "# filter cells\n",
    "#\n",
    "df = filter_cells(df, batch_names=batch_names, stats={})\n",
    "\n",
    "\n",
    "z_dfs = []\n",
    "for case in cases:\n",
    "    dir = f\"{run_name}/{case}_vs_{control}\"\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    #\n",
    "    # filter to target wells\n",
    "    #\n",
    "    control_wells = []\n",
    "    case_wells = []\n",
    "    target_wells = []\n",
    "    for well in well2label:\n",
    "        if control == well2label[well]:\n",
    "            control_wells.append(well)\n",
    "        if case == well2label[well]:\n",
    "            case_wells.append(well)\n",
    "    target_wells = control_wells + case_wells\n",
    "\n",
    "\n",
    "    case_df = df.loc[df[\"Well\"].isin(target_wells)]\n",
    "    case_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    norm_df = normalize_cells_by_aggregated_counts(case_df, batch_names=batch_names)\n",
    "    well_names = get_wells(norm_df)\n",
    "    norm_df = normalize_wells_by_median_of_ratios(norm_df, batch_names = batch_names, well_names = well_names)\n",
    "\n",
    "    all_targets = []\n",
    "    all_zs = []\n",
    "\n",
    "    #\n",
    "    # Calculate SD estimate from MAD\n",
    "    #\n",
    "    shared_sds = []\n",
    "    for batch_name in batch_names:\n",
    "        targets = get_default_normalization_targets(norm_df, batch_name)\n",
    "        control_values = []\n",
    "        case_values = []\n",
    "        for target in targets:\n",
    "            control_values.append(np.log2(np.nanmean(norm_df.loc[norm_df[\"Well\"].isin(control_wells), target])))\n",
    "            case_values.append(np.log2(np.nanmean(norm_df.loc[norm_df[\"Well\"].isin(case_wells), target])))\n",
    "        \n",
    "        shared_sd = 1.4826 * np.nanmedian(np.abs(np.array(control_values) - np.array(case_values)))\n",
    "        shared_sds.append(shared_sd)\n",
    "    shared_sd = np.nanmedian(shared_sds)\n",
    "\n",
    "    min_value = float(\"nan\")\n",
    "    max_value = float(\"nan\")\n",
    "\n",
    "    for batch_name in batch_names:\n",
    "        targets = get_default_normalization_targets(norm_df, batch_name)\n",
    "        control_values = []\n",
    "        case_values = []\n",
    "        for target in targets:\n",
    "            control_values.append(np.log2(np.nanmean(norm_df.loc[norm_df[\"Well\"].isin(control_wells), target])))\n",
    "            case_values.append(np.log2(np.nanmean(norm_df.loc[norm_df[\"Well\"].isin(case_wells), target])))\n",
    "      \n",
    "        min_value = np.nanmin(list(control_values) + list(case_values) + [min_value,])\n",
    "        max_value = np.nanmax(list(control_values) + list(case_values) + [max_value,])\n",
    "        \n",
    "        plt.scatter(control_values, case_values, label=batch_name)\n",
    "\n",
    "        all_targets.extend(targets)\n",
    "        all_zs.extend((np.array(case_values) - np.array(control_values))/shared_sd)    \n",
    "    \n",
    "    #\n",
    "    # Add identity line\n",
    "    #\n",
    "    plt.plot([min_value, max_value], [min_value, max_value], color=\"black\")\n",
    "\n",
    "    #\n",
    "    # Added dotted lines to plot for ~3 standard deviations\n",
    "    #\n",
    "    plt.plot([min_value + 3 * shared_sd, max_value + 3 * shared_sd], [min_value, max_value ], color = \"red\", linestyle=\"--\") \n",
    "    plt.plot([min_value - 3 * shared_sd, max_value - 3 * shared_sd], [min_value, max_value ], color = \"red\", linestyle=\"--\")\n",
    "\n",
    "    \n",
    "    plt.title(f\"{run_name}\")\n",
    "    plt.xlabel(f\"log2 {control}\")\n",
    "    plt.ylabel(f\"log2 {case}\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{dir}/{control}_vs_{case}.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    z_df = pd.DataFrame.from_dict({\"Target\" : all_targets, f\"Z_{case}\" : all_zs})\n",
    "    z_dfs.append(z_df)\n",
    "\n",
    "#\n",
    "# Output merged table of empirical Z values\n",
    "#\n",
    "z_df = z_dfs[0]\n",
    "for other_df in z_dfs[1:]:\n",
    "    z_df = z_df.merge(other_df, on=\"Target\")\n",
    "z_df.to_csv(f\"{run_name}/z_values.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
